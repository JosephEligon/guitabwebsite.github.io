# GuiTabs
### an automatic guitar transcription service written by David Hofferber, Joseph Eligon, Joshua Fields

### Contact Us
David Hofferber2020@u.northwestern.edu
JosephEligon2019@u.northwestern.edu
JoshuaFields2019@u.northwestern.edu

part of Machine Perception of Audio and Music at Northwestern University

## Synopsis of Work

### Motivation
People want to be able to play music, and the majority of the guitar repertoire is only available as audio

Manual transcription can often take a long time and is also difficult for beginners

### Problems
Most transcriptions needs to be done based on the audio because transcriptions are not commonly available. However, pitch tracking is a difficult task in itself

Even discounting the different positions your hand can be in while playing notes on the guitar, there are still five or six different ways to play every note

Even though the notes are important, the fingerings are probably the most important part of the song in order to be viable to play. However, due to the complexity of the fingering, much of how the fingerings are determined depend upon complex distance metrics

### Pipeline
1. The user indicates an audio file to transcribe
2. We run CREPE on the audio file, determining new notes based off of having a sufficient change in Hz. If CREPE is not confident for too long, we also terminate the current note.
3. Using the note list generated by CREPE, we identify an optimal fingering by performing a shortest path algorithm on a graph representation of the finger pattern.
4. Using the optimal fingerings, we use Muse Score in order to transcribe the notes in tablature, and generate a pdf of it

![Flowchart of our pipeline](https://raw.githubusercontent.com/guitabwebsite/guitabwebsite.github.io/master/images/pipeline.png)


### Details on Fingering Algorithm

We initially parse our song with 𝑘 notes into a graph structure of 𝑘+2 layers, where each vertex is a way to play the 𝑖^𝑡ℎ note.

We then connect each vertex layer to the next vertex layer with directed edges, where weights are assigned by a distance metric between note tuples

Once we have our finalized graph, we perform Dijkstra’s Algorithm to find the shortest path through the graph based on the weighted edges, which returns the fingerings which require the least movement based on our distance metrics.

![Visualization of graph from algorithm](https://raw.githubusercontent.com/guitabwebsite/guitabwebsite.github.io/master/images/algorithmgraph.png)
The vertex layers of our song, where 𝑣_𝑆 is a special node representing the start of our graph structure, 𝑣_𝐸 is a special node representing the end of our graph structure.


### Results
We were able to successfully transcribe audio into notated guitar tablature. However, that audio had to be monophonic, have very little noise, and be of 16-bit depth. The results were also not always perfect, as a few notes were sometimes an octave off due to our pitch tracker CREPE having trouble determining the octave. Although it should be noted that pitch trackers in general have this issue. Our fingering algorithm will often put emphasis of shifting hand positions and using the pinky instead of using the ring finger and shifting at a later time. This can be a bit uncomfortable for many guitarists.

![Output using Lilypond for tablature](https://raw.githubusercontent.com/guitabwebsite/guitabwebsite.github.io/master/images/lilyTab.png)
LilyPond tab generation

![Output using GuiTabs for tablature](https://raw.githubusercontent.com/guitabwebsite/guitabwebsite.github.io/master/images/GuiTab.png)
GuiTab tab generation

<audio><source="https://raw.githubusercontent.com/guitabwebsite/guitabwebsite.github.io/master/audio/test1aud.wav" type="audio/wav"></audio>

test2

### Evaluation Metrics
We evaluated our results based on their pitch accuracy to the actual notes. This was done through human feedback, where the user told us whether or not the pitches sound right.

We evaluated our results based on the fingerings ease of playability. This was done by having several guitar players play the generated tablature and give feedback on how natural it was for them to play it.

## Additional Information

### Motivation
People want to be able to play music, and the majority of the guitar repertoire is only available as audio

Manual transcription can often take a long time and is also difficult for beginners

### Related Work
Bello and Monti in “Techniques for Automatic Music Transcription” give a rough blueprint of producing audio transcriptions from audio and some methods that we have not endeavored to use in this project.

Dlabal and Wedeen in “Generating Sheet Music From Audio Files” give their approach for going from audio to notes and give some detailed note-detection information

Barbancho, et. Al in “Automatic Transcription of Guitar Chords and Fingering” discusses a way of feature extraction from many guitar samples to glean useful metrics for potential fingerings.

Tuohy and Walter describe a method to generate guitar tabs for audio including chords, but do not have fingerings.

### Future Work
In the future, we could fine tune weights of fingering graph or use an alternative machine learning approach, as well as integrate beat onsets in pitch tracking.

In an ideal world, we would make GuiTabs capable of polyphonic input.





